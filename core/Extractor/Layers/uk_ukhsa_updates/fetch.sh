#!/bin/bash
# uk_ukhsa_updates è³‡æ–™æ“·å–è…³æœ¬
# åŠŸèƒ½:ä¸‹è¼‰ UKHSA 3 å€‹ Atom/RSS feeds ä¸¦åˆä½µç‚ºå–®ä¸€ JSONL
# ç›¸å®¹ Bash 3.2ï¼ˆmacOS é è¨­ç‰ˆæœ¬ï¼‰

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/../../../.." && pwd)"

source "$PROJECT_ROOT/lib/args.sh"
source "$PROJECT_ROOT/lib/core.sh"
source "$PROJECT_ROOT/lib/rss.sh"

LAYER_NAME="uk_ukhsa_updates"
RAW_DIR="$PROJECT_ROOT/docs/Extractor/$LAYER_NAME/raw"

# Feed URLsï¼ˆä½¿ç”¨é™£åˆ—ï¼ŒBash 3.2 ç›¸å®¹ï¼‰
FEED_NAMES=(
    "ukhsa_official"
    "ukhsa_news"
    "ukhsa_blog"
)

FEED_URLS=(
    "https://www.gov.uk/government/organisations/uk-health-security-agency.atom"
    "https://www.gov.uk/search/news-and-communications.atom?organisations%5B%5D=uk-health-security-agency"
    "https://ukhsa.blog.gov.uk/feed/"
)

mkdir -p "$RAW_DIR"

echo "ğŸ“¥ [$LAYER_NAME] é–‹å§‹æ“·å– UKHSA feeds..."

TIMESTAMP=$(date +%Y%m%d-%H%M%S)
MERGED_JSONL="$RAW_DIR/merged-$TIMESTAMP.jsonl"
TOTAL_ITEMS=0
FAILED_FEEDS=()

# æ¸…ç©ºåˆä½µæª”æ¡ˆ
> "$MERGED_JSONL"

# Atom è½‰ JSONL å‡½æ•¸
atom_extract_items_jsonl() {
    local xml_file="$1"

    require_cmd jq || return 1

    if command -v xmllint >/dev/null 2>&1; then
        # ä½¿ç”¨ xmllint è§£æ Atom
        local count
        count="$(xmllint --xpath 'count(//*[local-name()="entry"])' "$xml_file" 2>/dev/null)" || return 1

        for ((i=1; i<=count; i++)); do
            local title link description pubDate
            title="$(xmllint --xpath "string(//*[local-name()='entry'][$i]/*[local-name()='title'])" "$xml_file" 2>/dev/null || echo "")"
            link="$(xmllint --xpath "string(//*[local-name()='entry'][$i]/*[local-name()='link']/@href)" "$xml_file" 2>/dev/null || echo "")"
            description="$(xmllint --xpath "string(//*[local-name()='entry'][$i]/*[local-name()='summary'])" "$xml_file" 2>/dev/null || echo "")"

            # å¦‚æœ summary ç‚ºç©ºï¼Œå˜—è©¦ content
            if [[ -z "$description" ]]; then
                description="$(xmllint --xpath "string(//*[local-name()='entry'][$i]/*[local-name()='content'])" "$xml_file" 2>/dev/null || echo "")"
            fi

            # å„ªå…ˆä½¿ç”¨ updatedï¼Œå…¶æ¬¡ published
            pubDate="$(xmllint --xpath "string(//*[local-name()='entry'][$i]/*[local-name()='updated'])" "$xml_file" 2>/dev/null || echo "")"
            if [[ -z "$pubDate" ]]; then
                pubDate="$(xmllint --xpath "string(//*[local-name()='entry'][$i]/*[local-name()='published'])" "$xml_file" 2>/dev/null || echo "")"
            fi

            jq -c -n \
                --arg title "$title" \
                --arg link "$link" \
                --arg description "$description" \
                --arg pubDate "$pubDate" \
                '{title: $title, link: $link, description: $description, pubDate: $pubDate}'
        done
    else
        echo "âš ï¸  xmllint ä¸å¯ç”¨ï¼Œä½¿ç”¨ç°¡æ˜“è§£æ" >&2
        # å›é€€åˆ°ç°¡æ˜“ sed è§£æï¼ˆè¼ƒä¸å¯é ï¼‰
        rss_extract_items_jsonl "$xml_file"
    fi
}

# é€ä¸€è™•ç†æ¯å€‹ feed
for idx in "${!FEED_NAMES[@]}"; do
    feed_name="${FEED_NAMES[$idx]}"
    feed_url="${FEED_URLS[$idx]}"
    xml_file="$RAW_DIR/feed-${feed_name}-$TIMESTAMP.xml"

    echo "ğŸ“¥ [$LAYER_NAME] ä¸‹è¼‰ $feed_name feed..."

    # ä¸‹è¼‰ feed
    if ! rss_fetch "$feed_url" "$xml_file"; then
        echo "âš ï¸  [$LAYER_NAME] $feed_name feed ä¸‹è¼‰å¤±æ•—ï¼Œè·³é" >&2
        FAILED_FEEDS+=("$feed_name")
        continue
    fi

    # é©—è­‰ feedï¼ˆRSS æˆ– Atom éƒ½æ‡‰é€šéï¼‰
    if ! rss_validate "$xml_file"; then
        echo "âš ï¸  [$LAYER_NAME] $feed_name feed æ ¼å¼ç„¡æ•ˆï¼Œè·³é" >&2
        FAILED_FEEDS+=("$feed_name")
        rm -f "$xml_file"
        continue
    fi

    # åˆ¤æ–·æ˜¯ Atom é‚„æ˜¯ RSS
    is_atom=false
    if grep -q '<feed' "$xml_file" 2>/dev/null; then
        is_atom=true
    fi

    # è½‰æ›ç‚º JSONL
    tmp_jsonl="$(mktemp)"

    if [[ "$is_atom" == "true" ]]; then
        atom_extract_items_jsonl "$xml_file" > "$tmp_jsonl"
    else
        rss_extract_items_jsonl "$xml_file" > "$tmp_jsonl"
    fi

    item_count=$(wc -l < "$tmp_jsonl" | tr -d ' ')
    echo "ğŸ“Š [$LAYER_NAME] $feed_name: $item_count ç­†"

    # åŠ å…¥ feed_source æ¬„ä½ä¸¦åˆä½µ
    while IFS= read -r line; do
        echo "$line" | jq -c --arg src "$feed_name" '. + {feed_source: $src}'
    done < "$tmp_jsonl" >> "$MERGED_JSONL"

    rm -f "$tmp_jsonl"
    TOTAL_ITEMS=$((TOTAL_ITEMS + item_count))
done

# çµ±è¨ˆçµæœ
MERGED_COUNT=$(wc -l < "$MERGED_JSONL" | tr -d ' ')

echo ""
echo "ğŸ“Š [$LAYER_NAME] åˆä½µçµæœ:"
echo "   - æˆåŠŸ feeds: $((${#FEED_NAMES[@]} - ${#FAILED_FEEDS[@]}))/${#FEED_NAMES[@]}"
echo "   - åˆä½µç­†æ•¸: $MERGED_COUNT"

if [[ ${#FAILED_FEEDS[@]} -gt 0 ]]; then
    echo "   - å¤±æ•— feeds: ${FAILED_FEEDS[*]}"
fi

# å»é‡ï¼ˆby linkï¼‰
if [[ $MERGED_COUNT -gt 0 ]]; then
    DEDUP_JSONL="$RAW_DIR/dedup-$TIMESTAMP.jsonl"
    sort -u -t'"' -k4 "$MERGED_JSONL" > "$DEDUP_JSONL"
    DEDUP_COUNT=$(wc -l < "$DEDUP_JSONL" | tr -d ' ')

    if [[ $DEDUP_COUNT -lt $MERGED_COUNT ]]; then
        echo "   - å»é‡å¾Œ: $DEDUP_COUNT ç­†ï¼ˆç§»é™¤ $((MERGED_COUNT - DEDUP_COUNT)) é‡è¤‡ï¼‰"
        mv "$DEDUP_JSONL" "$MERGED_JSONL"
    else
        rm -f "$DEDUP_JSONL"
    fi
fi

# è¨˜éŒ„æœ€å¾Œæ“·å–æ™‚é–“
echo "$(date -Iseconds)" > "$RAW_DIR/.last_fetch"

echo ""
echo "âœ… [$LAYER_NAME] Fetch å®Œæˆ: $MERGED_JSONL"
